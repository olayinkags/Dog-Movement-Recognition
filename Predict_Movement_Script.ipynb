{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24981ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only run this if your are using google collab if not skip this cell\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0619a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_behaviors_from_file(sensor_path, doginfo_path, model_path, label_encoder_path, scaler_seq_path, scaler_meta_path):\n",
    "    \"\"\"\n",
    "    Predict dog behaviors from new sensor data using trained model.\n",
    "    Returns a list of predicted labels.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import joblib\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorflow.keras.layers import LSTM\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "    # === Custom LSTM handler to fix time_major error ===\n",
    "    def lstm_without_time_major(*args, **kwargs):\n",
    "        kwargs.pop('time_major', None)  # Remove problematic argument\n",
    "        return LSTM(*args, **kwargs)\n",
    "\n",
    "    # === Load new data ===\n",
    "    sensor_cols = ['DogID', 'ANeck_x', 'ANeck_y', 'ANeck_z', 'GNeck_x', 'GNeck_y', 'GNeck_z']\n",
    "    raw_df = pd.read_csv(sensor_path)\n",
    "\n",
    "    has_label = 'Behavior_1' in raw_df.columns\n",
    "    if has_label:\n",
    "        sensor_cols.append('Behavior_1')\n",
    "\n",
    "    sensor_data = raw_df[sensor_cols].dropna()\n",
    "\n",
    "    if has_label:\n",
    "        sensor_data = sensor_data[~sensor_data['Behavior_1'].isin(['<undefined>', 'Synchronization', 'Extra_Synchronization'])]\n",
    "\n",
    "    doginfo = pd.read_excel(doginfo_path)\n",
    "\n",
    "    # === Preprocess metadata ===\n",
    "    doginfo['Weight'] /= doginfo['Weight'].max()\n",
    "    doginfo['Age months'] /= doginfo['Age months'].max()\n",
    "    doginfo = pd.get_dummies(doginfo, columns=['Breed', 'Gender', 'NeuteringStatus'])\n",
    "\n",
    "    # Merge sensor + metadata\n",
    "    full_df = pd.merge(sensor_data, doginfo, on='DogID', how='left')\n",
    "\n",
    "    # === Create sequences ===\n",
    "    def create_sequences(df, window_size=100, step=20):\n",
    "        sequences, meta_features, labels = [], [], []\n",
    "        feature_cols = ['ANeck_x', 'ANeck_y', 'ANeck_z', 'GNeck_x', 'GNeck_y', 'GNeck_z']\n",
    "        static_cols = [col for col in df.columns if col not in feature_cols + ['DogID', 'Behavior_1']]\n",
    "\n",
    "        for i in range(0, len(df) - window_size, step):\n",
    "            window = df.iloc[i:i+window_size]\n",
    "            if window['DogID'].nunique() > 1:\n",
    "                continue\n",
    "\n",
    "            label = window['Behavior_1'].iloc[window_size // 2] if has_label else None\n",
    "\n",
    "            sequences.append(window[feature_cols].values)\n",
    "            meta_features.append(window[static_cols].iloc[0].values)\n",
    "            labels.append(label)\n",
    "\n",
    "        return np.array(sequences), np.array(meta_features), np.array(labels)\n",
    "\n",
    "    X_seq_new, X_meta_new, y_true_raw = create_sequences(full_df)\n",
    "\n",
    "    if len(X_seq_new) == 0:\n",
    "        print(\"‚ùå Not enough data or inconsistent DogID in sequences.\")\n",
    "        return []\n",
    "\n",
    "    # === Scale inputs ===\n",
    "    scaler_seq = joblib.load(scaler_seq_path)\n",
    "    X_seq_flat = X_seq_new.reshape(-1, X_seq_new.shape[-1])\n",
    "    X_seq_scaled = scaler_seq.transform(X_seq_flat).reshape(X_seq_new.shape)\n",
    "\n",
    "    scaler_meta = joblib.load(scaler_meta_path)\n",
    "    X_meta_scaled = scaler_meta.transform(X_meta_new)\n",
    "\n",
    "    # === Load model with custom LSTM handler ===\n",
    "    custom_objects = {'LSTM': lstm_without_time_major}\n",
    "    try:\n",
    "        model = load_model(model_path, custom_objects=custom_objects)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Model loading failed: {str(e)}\")\n",
    "        print(\"Trying fallback without custom objects...\")\n",
    "        model = load_model(model_path)  # Fallback attempt\n",
    "\n",
    "    label_encoder = joblib.load(label_encoder_path)\n",
    "\n",
    "    # === Predict ===\n",
    "    y_pred_probs = model.predict([X_seq_scaled, X_meta_scaled])\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    print(\"‚úÖ Predictions completed.\\n\")\n",
    "\n",
    "    # === Evaluation ===\n",
    "    if has_label and y_true_raw[0] is not None:\n",
    "        y_true_encoded = label_encoder.transform(y_true_raw)\n",
    "\n",
    "        accuracy = accuracy_score(y_true_encoded, y_pred)\n",
    "        print(f\"‚úÖ Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "        print(\"üîç Classification Report:\")\n",
    "        print(classification_report(\n",
    "        y_true_encoded, \n",
    "        y_pred,\n",
    "        labels=np.unique(y_true_encoded),  # Only use present classes\n",
    "        target_names=label_encoder.classes_[np.unique(y_true_encoded)]  # Corresponding names\n",
    "        ))\n",
    "\n",
    "        cm = confusion_matrix(y_true_encoded, y_pred)\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                   xticklabels=label_encoder.classes_, \n",
    "                   yticklabels=label_encoder.classes_)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Skipped evaluation metrics because true labels were not provided.\\n\")\n",
    "\n",
    "    return y_pred_labels.tolist(), y_true_raw.tolist() if has_label else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f54fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace sensor_path with the new sensor-data path on your pc or drive\n",
    "# Replace doginfo_path iwth the new doginfo data path on your pc or drive\n",
    "\n",
    "predict_behaviors_from_file(\n",
    "    sensor_path=sensor_path,\n",
    "    doginfo_path=doginfo_path,\n",
    "    model_path=\"dog_movement_model.h5\",\n",
    "    label_encoder_path=\"labelEncoder.pkl\",\n",
    "    scaler_seq_path = \"scaler_seq.pkl\",\n",
    "    scaler_meta_path = \"scaler_meta.pkl\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
